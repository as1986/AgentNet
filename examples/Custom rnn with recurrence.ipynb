{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What am i?\n",
    "\n",
    "This is just a reference notebok showcasing how to write custom RNN steps in lasagne.\n",
    "It follows `char_rnn.ipynb` right until the network composition phase.\n",
    "\n",
    "You are invited to skip to that phase and read through what's defined there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate names\n",
    "* Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertise over what is a good child name, so let us train NN instead.\n",
    "* Dataset contains ~8k human names from different cultures[in latin transcript]\n",
    "* Objective (toy problem): learn a generative model over names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_token = \" \"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token+name for name in names]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n samples = ', 7944)\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print ('n samples = ',len(names))\n",
    "for x in names[::1000]:\n",
    "    print( x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('n_tokens = ', 55)\n"
     ]
    }
   ],
   "source": [
    "tokens = list(set(''.join(names)))\n",
    "\n",
    "print ('n_tokens = ',len(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!token_to_id = <dictionary of symbol -> its identifier (index in tokens list)>\n",
    "token_to_id = {t:i for i,t in enumerate(tokens) }\n",
    "\n",
    "#!id_to_token = < dictionary of symbol identifier -> symbol itself>\n",
    "id_to_token = {i:t for i,t in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_ix = list(map(lambda name: list(map(token_to_id.get,name)),names))\n",
    "\n",
    "MAX_LEN = 16\n",
    "#crop long names and pad short ones\n",
    "for i in range(len(names_ix)):\n",
    "    names_ix[i] = names_ix[i][:MAX_LEN] #crop too long\n",
    "    \n",
    "    if len(names_ix[i]) < MAX_LEN:\n",
    "        names_ix[i] += [token_to_id[\" \"]]*(MAX_LEN - len(names_ix[i])) #pad too short\n",
    "        \n",
    "assert len(set(map(len,names_ix)))==1\n",
    "\n",
    "names_ix = np.array(names_ix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "\n",
    "import agentnet\n",
    "from agentnet import Recurrence\n",
    "agentnet.config.shut_up() #disable warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence = T.matrix('token sequence','int64')\n",
    "\n",
    "inputs = sequence[:,:-1]\n",
    "targets = sequence[:,1:]\n",
    "\n",
    "\n",
    "l_input_sequence = InputLayer(shape=(None, None),input_var=inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build NN\n",
    "\n",
    "You'll be building a model that takes token sequence and predicts next tokens at each tick\n",
    "\n",
    "This is basically equivalent to how rnn step was described in the lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.memory import GRUCell,LSTMCell,RNNCell\n",
    "from agentnet.resolver import ProbabilisticResolver\n",
    "\n",
    "###One step of rnn\n",
    "class step:\n",
    "    \n",
    "    #inputs\n",
    "    inp = InputLayer((None,),name='current character')\n",
    "    h_prev = InputLayer((None,64),name='previous rnn state')\n",
    "    \n",
    "    #recurrent part\n",
    "    emb = EmbeddingLayer(inp,len(tokens),16)\n",
    "    \n",
    "    h_new = DenseLayer(concat([h_prev,emb]),64,nonlinearity=T.tanh)\n",
    "    #same: h_new = RNNCell(h_prev,emb)\n",
    "    \n",
    "    next_token_probas = DenseLayer(h_new,len(tokens),nonlinearity=T.nnet.softmax)\n",
    "    \n",
    "    #pick next token from predicted probas\n",
    "    next_token = ProbabilisticResolver(next_token_probas)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurrence, explained\n",
    "\n",
    "You can use `Recurrence` to define a custom recurrent layer for lasagne, defined by a single-step graph.\n",
    "\n",
    "In the example below, we use define three types of layers:\n",
    "* __state_variables__: a dict of `{layer: becomes_this_on_next_step}`\n",
    "* __input_sequences__: a dict of `{layer: iterates_over_axis1_of_this_layer`}\n",
    "* __tracked_outputs__: a list of layers you want to access layer (i.e. outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_loop = Recurrence(\n",
    "    state_variables={step.h_new:step.h_prev},    # ~ h_new becomes h_prev on next tick\n",
    "    input_sequences={step.inp:l_input_sequence}, # ~ inp iterates over l_input_sequence axis 1\n",
    "    tracked_outputs=[step.next_token_probas,],   # ~ i want to access sequence of next_token_probas later\n",
    "    \n",
    "    unroll_scan=False,                           # same as in lasagne. if True, compiles longer, but runs faster\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the recurrence defined above won't compute `next_token` or compute any layer not required to compute `tracked_outputs` or `state_variables`.\n",
    "\n",
    "You can also use three other types (not covered here):\n",
    "* __input_nonsequences__: a dict of `{layer: is_equal_to_this_layer_on_every_tick}`\n",
    "* __state_init__: a dict of `{state_variables key: is_equal_to_this_before_first_tick}`, defaults to zeros\n",
    "* __mask_input__: same as mask_input in lasagne recurrent layers. If equal to 0, skips this turn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use Recurrence as any other lasagne layer. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, W, b, W, b]\n"
     ]
    }
   ],
   "source": [
    "# Model weights\n",
    "weights = lasagne.layers.get_all_params(training_loop,trainable=True)\n",
    "print (weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a sequence of outputs or state values from recurrence using a simple syntax below.\n",
    "\n",
    "__l_probs_seq__ is a Lasagne layer that can be fed into another layer or used as network output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#layer with \"next token probas\" at each tick, shape = [batch,time,n_tokens]\n",
    "l_probs_seq = training_loop[step.next_token_probas]\n",
    "\n",
    "assert isinstance(l_probs_seq,Layer)\n",
    "\n",
    "#symbolic output\n",
    "predicted_probabilities = lasagne.layers.get_output(l_probs_seq)\n",
    "\n",
    "#If you use dropout do not forget to create deterministic version for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, one can request `training_loop[step.h_new]` to get RNN states on each tick.\n",
    "\n",
    "However, if you request a tensor this way, make sure it's either in `state_variables` or `tracked_outputs`.\n",
    "\n",
    "For the sake of this demo, we proceed by defining loss function and updates using lasagne builtins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#<Loss function - a simple categorical crossentropy will do, maybe add some regularizer>\n",
    "loss = lasagne.objectives.categorical_crossentropy(predicted_probabilities.reshape((-1,len(tokens))),\n",
    "                                                   targets.reshape((-1,))\n",
    "                                                  ).mean()\n",
    "\n",
    "updates = lasagne.updates.adam(loss,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling\n",
    "\n",
    "Again, we compile a training function in the same fashion as in [lasagne tutorial](https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py).\n",
    "\n",
    "The only difference here is that we call `training_loop.get_automatic_updates()`. \n",
    "\n",
    "We need them because that's how theano handles randomness (at least <=v0.9.0). Automatic updates are updates for random states and default updates [(example)](https://github.com/Lasagne/Lasagne/blob/b0940946f9c48aa3a7aaaf0df2aafe77cd17af9a/lasagne/layers/normalization.py#L295-L299).\n",
    "\n",
    "With default RNN implementation, you can drop this line since __we don't require any auto-updates yet__, but if you choose to add dropout or noize, you will require the automatic updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#training\n",
    "train_step = theano.function([sequence], loss,\n",
    "                             updates=updates+training_loop.get_automatic_updates())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative mode\n",
    "\n",
    "Here we re-wire the recurrent network so that it's output is fed back to it's input. This is useful for generating sequences.\n",
    "\n",
    "Unlike previous recurrence,\n",
    "* there's a second recurrent state: `next_token` is fed back into `inp`\n",
    "* there's no `input_sequences` this time\n",
    "* we have to explicitly provide n_steps and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_steps = T.scalar(dtype='int32')\n",
    "feedback_loop = Recurrence(\n",
    "    state_variables={step.h_new:step.h_prev,\n",
    "                     step.next_token:step.inp},\n",
    "    tracked_outputs=[step.next_token_probas,step.next_token],\n",
    "    batch_size=theano.shared(1),\n",
    "    n_steps=n_steps,\n",
    "    unroll_scan=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed by compiling a function that generates a sequence of indices.\n",
    "\n",
    "This time we __require automatic updates__ because the recurrence involves random sample from token probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "generated_tokens = get_output(feedback_loop[step.next_token])\n",
    "\n",
    "generate_sample = theano.function([n_steps],generated_tokens,\n",
    "                                  updates=feedback_loop.get_automatic_updates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_string(length=MAX_LEN):\n",
    "    \"\"\"generate random sequence up to the given length\"\"\"\n",
    "    output_indices = generate_sample(length)[0]\n",
    "    return ''.join(tokens[i] for i in output_indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lE rNJbmxTEkSaAo\n"
     ]
    }
   ],
   "source": [
    "#test it on a non-trained network\n",
    "print(generate_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "Our lil'RNN is trained on random minibatches of data using the training function we defined above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_batch(data, batch_size):\n",
    "    rows = data[np.random.randint(0,len(data),size=batch_size)]\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch 0 average loss = 1.45295459339\n",
      "Generated names\n",
      "Harye           \n",
      "Kdt ne          \n",
      "Muctia          \n",
      "qariis          \n",
      "Freme           \n",
      "Jariele         \n",
      "Goriele         \n",
      "Jlntitee        \n",
      "Rnvgkur         \n",
      "Ganiend         \n",
      "\n",
      "\n",
      "Epoch 1 average loss = 1.13703199921\n",
      "Generated names\n",
      "Mvaynih         \n",
      "Jonnli          \n",
      "Beoeeine        \n",
      "Sumo            \n",
      "Aviy            \n",
      "Wury            \n",
      "Nrfa            \n",
      "Marelena        \n",
      "Nasulo          \n",
      "Begalarer       \n",
      "\n",
      "\n",
      "Epoch 2 average loss = 1.09981673085\n",
      "Generated names\n",
      "Mell            \n",
      "Bery            \n",
      "Mal             \n",
      "Baa             \n",
      "byynthoore      \n",
      "Monta           \n",
      "Swra            \n",
      "Ary             \n",
      "Emfig           \n",
      "Restiegl        \n",
      "\n",
      "\n",
      "Epoch 3 average loss = 1.07280006848\n",
      "Generated names\n",
      "Mayna           \n",
      "Kellyd          \n",
      "Zlaneert        \n",
      "Leltone         \n",
      "Midbye          \n",
      "Erfy            \n",
      "Jerdi           \n",
      "AlrPie          \n",
      "Wweste          \n",
      "Alhane          \n",
      "\n",
      "\n",
      "Epoch 4 average loss = 1.05519196807\n",
      "Generated names\n",
      "Cipias          \n",
      "Comy            \n",
      "Alumeen         \n",
      "Crerty          \n",
      "Plebteo         \n",
      "Llni            \n",
      "Cuvea           \n",
      "Onnank          \n",
      "Shenr           \n",
      "Kedinne         \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c1f80813ed5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames_ix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\nEpoch {} average loss = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_cost\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatches_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jheuristic/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jheuristic/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jheuristic/anaconda2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                         self, node)\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#total N iterations\n",
    "n_epochs=10\n",
    "\n",
    "# how many minibatches are there in the epoch \n",
    "batches_per_epoch = 500\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    avg_cost = 0;\n",
    "    for _ in range(batches_per_epoch):\n",
    "        avg_cost += train_step(sample_batch(names_ix,batch_size=10))\n",
    "        \n",
    "    print(\"\\n\\nEpoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "\n",
    "    print (\"Generated names:\")\n",
    "    for i in range(10):\n",
    "        print(generate_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#random sample outputs\n",
    "for _ in range(50):\n",
    "    print(generate_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And now,\n",
    "* add temperature (shared or input)\n",
    "* try gru/lstm \n",
    " * mind that __lstm__ has two kinds of memory: cell(c) and output(h)\n",
    "* add several layers\n",
    "* try your own dataset of any kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
